{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M74Gs_TjYl_B"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mjavadpur/styleheat/blob/main/quick_demo.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/mjavadpur/StyleHEAT.git\n",
        "%cd StyleHEAT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ4CplXsYl_E"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Download pre-trained models...')\n",
        "!rm -rf checkpoints\n",
        "!bash /content/StyleHEAT/bash/download.sh\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Same-Identity Reenactment with a video.\n",
        "!python /content/StyleHEAT/inference.py \\\n",
        "            --config /content/StyleHEAT/configs/inference.yaml \\\n",
        "            --video_source=/content/StyleHEAT/docs/demo/videos/RD_Radio34_003_512.mp4 \\\n",
        "            --output_dir=/content/StyleHEAT/docs/demo/output --if_extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-Identity Reenactment with a single image and a video.\n",
        "# The --video_source and --image_source can be specified as either a single file or a folder.\n",
        "# For a better inversion result but taking more time, \n",
        "# please specify --inversion_option=optimize and we will optimize the feature latent of StyleGAN-V2. \n",
        "# Otherwise we will use HFGI encoder to get the style code and inversion condition with --inversion_option=encode.\n",
        "# If you need align (crop) images during the inference process, \n",
        "# please specify --if_align. Or you can first align the source images following FFHQ dataset.\n",
        "# If you need to extract the 3dmm parameters of the target video during the inference process,\n",
        "# please specify --if_extract. \n",
        "# Or you can first extract the 3dmm parameters with the script TODO.sh \n",
        "# and save the 3dmm in the {video_source}/3dmm/3dmm_{video_name}.npy\n",
        "# If you only need to edit the expression without modifying the pose, \n",
        "# please specify --edit_expression_only.\n",
        "!python inference.py \\\n",
        "            --config configs/inference.yaml \\\n",
        "            --video_source=./docs/demo/videos/RD_Radio34_003_512.mp4 \\\n",
        "            --image_source=./docs/demo/images/100.jpg \\\n",
        "            --cross_id --if_extract \\\n",
        "            --output_dir=./docs/demo/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intuitive Editing.\n",
        "# The 3dmm parameters of the images can also be pre-extracted or online-extracted with the parameter --if_extract.\n",
        "!python inference.py \\\n",
        "            --config configs/inference.yaml \\\n",
        "            --image_source=./docs/demo/images/40.jpg \\\n",
        "            --inversion_option=optimize \\\n",
        "            --intuitive_edit \\\n",
        "            --output_dir=./docs/demo/output \\\n",
        "            --if_extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attribute Editing.\n",
        "# The support editable attributes include young, old, beard, lip.\n",
        "# Note to preserve the editing attributes details in W space, \n",
        "# the optimized inversion method is banned here.\n",
        "!python inference.py \\\n",
        "            --config configs/inference.yaml \\\n",
        "            --video_source=./docs/demo/videos/RD_Radio34_003_512.mp4 \\\n",
        "            --image_source=./docs/demo/images/40.jpg \\\n",
        "            --attribute_edit --attribute=young \\\n",
        "            --cross_id \\\n",
        "            --output_dir=./docs/demo/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Audio Reenactment.\n",
        "# Please first install SadTalker in the folder of third_part as the format of third_part/SadTalker. \n",
        "# Download its pre-trained checkpoints according to their instructions. \n",
        "# Install the additional libraries with pip install pydub==0.25.1 \n",
        "# yacs==0.1.8 librosa==0.6.0 numba==0.48.0 resampy==0.3.1 imageio-ffmpeg==0.4.7. \n",
        "# Then you can run audio reenactment freely.\n",
        "!python inference.py \\\n",
        "            --config configs/inference.yaml \\\n",
        "            --audio_path=./docs/demo/audios/RD_Radio31_000.wav \\\n",
        "            --image_source=./docs/demo/images/100.jpg \\\n",
        "            --cross_id --if_extract \\\n",
        "            --output_dir=./docs/demo/output \\\n",
        "            --inversion_option=optimize"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "db5031b3636a3f037ea48eb287fd3d023feb9033aefc2a9652a92e470fb0851b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
